# **DEVELOPMENT NOTES  ||  Team Webelistics™️, LLC**
##### **Date:** 2024-04-13


### Researching Puppeteer and Headless Chrome

-   Scraping Pick 3 SC Lottery numbers / [SC Education Lottery/Pick3](https://www.sceducationlottery.com/Games/Pick3)

- Code for converting scrape text to JSON in Node.js
- ![](https://miro.medium.com/v2/resize:fit:630/1*j_SVP_vcI4QhOuCi9fBHEw.png) ![](https://miro.medium.com/v2/resize:fit:630/1*fwyarsAOQMeW7czM3SMnAg.png)  

-   From file /  [Web Scrapping with Puppeteer — Some basic examples](../md/puppeteer_docs/!_scrape_web_Puppeteer_simple_examples.md)
-   JavaScript code for scraping a website with Puppeteer || The final runnable code looks like this. We could also increase REPO_COUNT back to 100 to get the top 100 JavaScript repositories, but this will most likely lead to getting your IP rate limited by GitHub. So let's increase it only to 40. You can use proxies to deal with the rate limit 
  
```javascript
import { PuppeteerCrawler, Request, Dataset } from 'crawlee';

const REPO_COUNT = 40;

const crawler = new PuppeteerCrawler({
    requestHandler: async ({ request, page, infiniteScroll }) => {
        const title = await page.title()
        console.log(title);

        if (request.label === 'repository') {
            const commitCountSelector = 'span.d-none.d-sm-inline > strong';
            await page.waitForSelector(commitCountSelector);
            const commitText = await page.$eval(commitCountSelector, (el) => el.textContent);
            const numberStrings = commitText.match(/\d+/g);
            const commitCount = Number(numberStrings.join(''));

            await Dataset.pushData({
                ...request.userData,
                commitCount,
            });
        } else {
            await infiniteScroll({
                buttonSelector: 'text=Load more',
                stopScrollCallback: async () => {
                    const repos = await page.$$('article.border');
                    return repos.length >= REPO_COUNT;
                },
            });

            const repos = await page.$$eval('article.border', (repoCards) => {
                return repoCards.map(card => {
                    const [user, repo] = card.querySelectorAll('h3 a');
                    const stars = card.querySelector('#repo-stars-counter-star')
                        .getAttribute('title');
                    const description = card.querySelector('div.px-3 > p');
                    const topics = card.querySelectorAll('a.topic-tag');

                    const toText = (element) => element && element.innerText.trim();
                    const parseNumber = (text) => Number(text.replace(/,/g, ''));

                    return {
                        user: toText(user),
                        repo: toText(repo),
                        url: repo.href,
                        stars: parseNumber(stars),
                        description: toText(description),
                        topics: Array.from(topics)
                            .map((t) => toText(t)),
                    };
                });
            });

            console.log('Repository count:', repos.length);
            const requests = repos.map(repo => new Request({
                url: repo.url,
                label: 'repository',
                userData: repo,
            }));

            await crawler.addRequests(requests);
        }
    }
})

await crawler.run(['https://github.com/topics/javascript']);
await Dataset.exportToCSV('repositories');
```
-   From File:  _How to scrape the web with Puppeteer in **2023**_ / [!_How_scrape_web_Puppeteer_2023.md](../md/puppeteer_docs/!_How_scrape_web_Puppeteer_2023.md)
-   

### I'm going to try creating a class instead of a function 

-   Name the class ScrapePick3 and create a constructor